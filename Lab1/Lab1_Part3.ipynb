{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e5c4eb",
   "metadata": {},
   "source": [
    "# TP1 — Part 3: CNNs + Data Augmentation on MNIST (Rotation & Translation)\n",
    "\n",
    "**Course:** Deep Learning for Image Analysis / Computer Vision  \n",
    "**Goal:** Train a **CNN** on MNIST, **inspect its layers**, and show how **data augmentation** (rotation + translation) can improve robustness.\n",
    "\n",
    "In Part 2, we used an MLP and **flattened** images into vectors.  \n",
    "In Part 3, we use **CNNs** to exploit spatial structure **(1, 28, 28)** and we test a key idea in vision:  \n",
    "> If we train with rotated/translated images, the model generalizes better to these transformations.\n",
    "\n",
    "---\n",
    "## What you will do\n",
    "1. Train a baseline CNN on MNIST (no augmentation)\n",
    "2. Train the same CNN with **RandomAffine** augmentation (rotation + translation)\n",
    "3. Compare test accuracy on:\n",
    "   - **standard MNIST test**\n",
    "   - **transformed MNIST test** (rotated/translated)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e4852",
   "metadata": {},
   "source": [
    "## 0) Setup (Colab GPU)\n",
    "\n",
    "In Colab: **Runtime → Change runtime type → GPU**  \n",
    "Then run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793aa0",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b395d1",
   "metadata": {},
   "source": [
    "## 2) Data: MNIST + Augmentations\n",
    "\n",
    "We will create **four** dataset variants:\n",
    "\n",
    "1. **Train (no aug)**: standard MNIST training set  \n",
    "2. **Train (aug)**: MNIST with *rotation + translation* \n",
    "3. **Test (standard)**: standard MNIST test set  \n",
    "4. **Test (transformed)**: MNIST test set **with the same types of transforms** (to evaluate robustness)\n",
    "\n",
    "### Augmentation used\n",
    "- Rotation: up to ±35 degrees\n",
    "- Translation: up to 30% of the image size\n",
    "\n",
    "This simulates real-world variation (digits rarely appear perfectly centered).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4514ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Standard transform\n",
    "tfm_standard = transforms.ToTensor()\n",
    "\n",
    "# Augmentation: rotation + translation (applied during training)\n",
    "tfm_aug = transforms.Compose([\n",
    "   # Todo tansformations to be applied\n",
    "   #Todo think of using RandomAffine\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# \"Transformed test\" to measure robustness to these changes\n",
    "tfm_test_transformed = transforms.Compose([\n",
    "    #Todo same transformations as above\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_noaug =  # TDDO: import mnist train without augmentation \n",
    "train_aug   = # TDDO import mnist with augmentation\n",
    "\n",
    "test_std    =# TDDO: import mnist test without augmentation \n",
    "test_trans  = # TDDO: import mnist test without augmentation \n",
    "\n",
    "len(train_noaug), len(train_aug), len(test_std), len(test_trans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761ca91",
   "metadata": {},
   "source": [
    "### Quick visualization (standard vs augmented)\n",
    "\n",
    "If augmentation is working, you should see digits slightly rotated and shifted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(dataset, title, n=8):\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    for i in range(n):\n",
    "        img, label = dataset[i]\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "        plt.title(str(label))\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_noaug, \"MNIST (standard samples)\")\n",
    "show_samples(train_aug, \"MNIST (augmented samples: rotated/translated)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ea564",
   "metadata": {},
   "source": [
    "## 3) DataLoaders\n",
    "\n",
    "We'll use mini-batches. If you run out of memory, reduce `batch_size`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader_noaug = # TDDO : create the dataloader : we saw it in the first part\n",
    "train_loader_aug   =# TDDO \n",
    "\n",
    "test_loader_std    =# TDDO \n",
    "test_loader_trans  = # TDDO \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd3d48",
   "metadata": {},
   "source": [
    "## 4) CNN model\n",
    "\n",
    "A simple CNN for MNIST:\n",
    "\n",
    "- Conv(1→16) + ReLU + MaxPool\n",
    "- Conv(16→32) + ReLU + MaxPool\n",
    "- Flatten\n",
    "- FC(32×7×7 → 128) + ReLU\n",
    "- FC(128 → 10)\n",
    "\n",
    "This is intentionally small so it trains quickly on Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28x28 -> 14x14\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)   # 14x14 -> 7x7\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, # TDDO :  number of classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9e519",
   "metadata": {},
   "source": [
    "## 5) Training & evaluation utilities\n",
    "\n",
    "We use:\n",
    "- Loss: `CrossEntropyLoss` (10 classes)\n",
    "- Optimizer: `Adam`\n",
    "\n",
    "We'll train the same architecture twice:\n",
    "1) on standard MNIST (no aug)\n",
    "2) on augmented MNIST (rotation + translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2234cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = # TODO loss function \n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "       # TDDO : carete the training loop\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "# TODO:  before evaluating the model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in loader:\n",
    "\n",
    "        # TDDO evaluation loop\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8b469",
   "metadata": {},
   "source": [
    "## 6) Train baseline CNN (no augmentation)\n",
    "\n",
    "You can increase `epochs` if you wants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, epochs=3, lr=1e-3):\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "        va_loss, va_acc = evaluate(model, test_loader_std)\n",
    "\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"val_loss\"].append(va_loss)\n",
    "        history[\"val_acc\"].append(va_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | train_loss={tr_loss:.4f} train_acc={tr_acc:.3f} | test_std_acc={va_acc:.3f}\")\n",
    "    return model, history\n",
    "\n",
    "epochs = 3\n",
    "cnn_noaug, hist_noaug = # TDDO : train_model on the non-augmented data, choose a good learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776bd81",
   "metadata": {},
   "source": [
    "## 7) Train CNN with augmentation (rotation + translation)\n",
    "\n",
    "Augmentation often makes training harder (samples are more varied), but increases robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a006fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_aug, hist_aug = # TDDO : train_model on the augmented data, choose a good learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf61a47",
   "metadata": {},
   "source": [
    "## 8) Evaluate robustness\n",
    "\n",
    "We evaluate both models on:\n",
    "- Standard MNIST test set\n",
    "- Transformed MNIST test set (rotated/translated)\n",
    "\n",
    "A robust model should lose **less accuracy** on the transformed test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaug_std_loss, noaug_std_acc = # TDDO : evaluate on standard test set\n",
    "noaug_tr_loss,  noaug_tr_acc  = # TODO\n",
    "aug_std_loss,   aug_std_acc   = # TODO\n",
    "aug_tr_loss,    aug_tr_acc    = # TODO\n",
    "print(\"=== Baseline CNN (no augmentation) ===\")\n",
    "print(f\"Test (standard):    acc={noaug_std_acc:.3f}\")\n",
    "print(f\"Test (transformed): acc={noaug_tr_acc:.3f}\")\n",
    "print()\n",
    "print(\"=== CNN trained with augmentation ===\")\n",
    "print(f\"Test (standard):    acc={aug_std_acc:.3f}\")\n",
    "print(f\"Test (transformed): acc={aug_tr_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca1a16",
   "metadata": {},
   "source": [
    "### Plot training curves (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74446846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist, title):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(hist[\"train_acc\"], label=\"train_acc\")\n",
    "    plt.plot(hist[\"val_acc\"], label=\"test_std_acc\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(hist_noaug, \"CNN (no augmentation)\")\n",
    "plot_hist(hist_aug, \"CNN (with augmentation)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc080381",
   "metadata": {},
   "source": [
    "## 9) Visualizing CNN layers\n",
    "\n",
    "We will look at:\n",
    "1. **First-layer convolution filters** (weights of Conv1)\n",
    "2. **Feature maps (activations)** for a single image\n",
    "\n",
    "This helps you *see* what the CNN learns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_conv1_filters(model, max_filters=16):\n",
    "    conv1 = None\n",
    "    for layer in model.features:\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            conv1 = layer\n",
    "            break\n",
    "    W = conv1.weight.detach().cpu()  # (out_channels, in_channels, kH, kW)\n",
    "\n",
    "    n = min(W.shape[0], max_filters)\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(W[i, 0], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(\"Conv1 filters (learned 3×3 kernels)\")\n",
    "    plt.show()\n",
    "\n",
    "show_conv1_filters(cnn_aug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93421d28",
   "metadata": {},
   "source": [
    "### Feature maps (activations)\n",
    "\n",
    "We take **one test image**, pass it through the CNN, and visualize outputs after each convolution layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_activations(model, x):\n",
    "    activations = []\n",
    "    cur = x\n",
    "    for layer in model.features:\n",
    "        cur = layer(cur)\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            activations.append(cur.detach().cpu())\n",
    "    return activations\n",
    "\n",
    "# One sample from the standard test set\n",
    "img, label = test_std[0]\n",
    "x = img.unsqueeze(0).to(device)\n",
    "\n",
    "acts = get_activations(cnn_aug, x)\n",
    "\n",
    "print(\"Label:\", label)\n",
    "print(\"Activation shapes:\", [a.shape for a in acts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_maps(activation, title, max_maps=8):\n",
    "    C = activation.shape[1]\n",
    "    n = min(C, max_maps)\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(activation[0, i], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "for idx, act in enumerate(acts, start=1):\n",
    "    show_feature_maps(act, f\"Feature maps after Conv layer {idx}\", max_maps=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0221c7",
   "metadata": {},
   "source": [
    "## 10) Final reflection \n",
    "\n",
    "1. Compare **standard test accuracy** vs **transformed test accuracy** for both models. What do you notice?\n",
    "2. Why does augmentation help on the transformed test set?\n",
    "3. Do we always expect augmentation to improve standard test accuracy? Why/why not?\n",
    "\n",
    "**Conclusion:** In the next LAB(2), we will go deeper into CNN architectures, and you should see further accuracy improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058b69e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
